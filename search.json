[
  {
    "objectID": "registered_patients.html",
    "href": "registered_patients.html",
    "title": "Registered Patient Data",
    "section": "",
    "text": "library(rvest)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()         masks stats::filter()\n✖ readr::guess_encoding() masks rvest::guess_encoding()\n✖ dplyr::lag()            masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(tmap)\n\nFrom the NHS we can extract total number of patients registered after each month. This code downloads all monthly reports programmatically and extracts the zip files\n\nbase_u &lt;- \"https://digital.nhs.uk/data-and-information/publications/statistical/patients-registered-at-a-gp-practice/\"\n\nmy_grid &lt;- expand.grid(month = tolower(month.name),\n             year = 2020:2024\n             ) \nmy_grid$u &lt;- paste(my_grid$month,my_grid$year,sep = \"-\")\n\n# i &lt;-  my_grid$u[1]\nfolder_path &lt;- \"gp_patients\"\n\ndir.create(path = folder_path,showWarnings = F)\n\ncur_files &lt;- tools::file_path_sans_ext(list.files(folder_path))\n\nmy_grid &lt;- my_grid[!(my_grid$u %in% cur_files),]\n\nfor (i in my_grid$u){\n  print(paste0(base_u,i)) \n  w &lt;-read_html(paste0(base_u,i))\n  \n  links &lt;- w  |&gt; html_nodes(\"a\")  |&gt; html_attr(\"href\")\n  \n  my_link &lt;- links[grep(links,\n                        pattern = \"gp-reg-pat-prac-all\")]\n\n  download.file(url = my_link,destfile = paste0(folder_path,\"/\",i,\".\",tools::file_ext(my_link)),mode = \"wb\")\n  \n  Sys.sleep(rnorm(1,mean = 5))\n}\n\n# List all ZIP files in the folder\nzip_files &lt;- list.files(path = folder_path, pattern = \"\\\\.zip$\", full.names = TRUE)\n\n# Extract each ZIP file\nlapply(zip_files, function(zip_file) {\n  # Create a temporary directory for extraction\n  temp_dir &lt;- tempfile()\n  dir.create(temp_dir)\n  \n  # Extract the ZIP file into the temporary directory\n  unzip(zip_file, exdir = temp_dir)\n  \n  # List extracted files\n  extracted_files &lt;- list.files(path = temp_dir, full.names = TRUE)\n  \n  # Move and rename each extracted file to the original folder\n  lapply(extracted_files, function(file) {\n    file_extension &lt;- tools::file_ext(file)\n    new_name &lt;- file.path(folder_path, paste0(tools::file_path_sans_ext(basename(zip_file)), \".\", file_extension))\n    file.rename(file, new_name)\n  })\n  \n    \n  # Remove the temporary directory\n  unlink(temp_dir, recursive = TRUE)\n})\n\nLoading the data and consolidating it\n\nall_data &lt;- lapply(list.files(path = \"gp_patients\",pattern = \"\\\\.csv$\",full.names = T),\n       \\(x){\n         read_csv(x) |&gt; \n           mutate(month = str_extract(basename(x),\"[a-zA-Z]+(?=-)\"),\n                  year = str_extract(basename(x),\"\\\\d{4}\"))\n       })\n\n\ncommon_names &lt;- reduce(lapply(all_data,names),intersect)\n\nall_data_df &lt;- do.call(rbind,\n        lapply(all_data,\n       \\(x){\n         x[,common_names]\n})) |&gt; \n  mutate(year = as.integer(year))\n\n\nwrite_csv(all_data_df,file = \"practice_patients.csv\")\n\nA quick look at median size of each practice\n\nall_data_df |&gt; \n  summarise(across(NUMBER_OF_PATIENTS,\\(x) median(x,na.rm = T)),.by = CODE) |&gt;\n  ggplot(aes(NUMBER_OF_PATIENTS))+\n  geom_histogram(binwidth = 500)\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nThe spatial distribution\n\nsf_practices &lt;- st_read(\"practices_CAZ.gpkg\")\n\nReading layer `practices_CAZ' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\00_Misc_projects\\Eng-Presc-Data\\practices_CAZ.gpkg' \n  using driver `GPKG'\nSimple feature collection with 11864 features and 10 fields (with 4 geometries empty)\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 90774 ymin: 10282 xmax: 655043 ymax: 653236\nProjected CRS: OSGB36 / British National Grid\n\nsf_practices_size &lt;- sf_practices |&gt;\n  left_join(all_data_df |&gt; \n  summarise(across(NUMBER_OF_PATIENTS,\\(x) median(x,na.rm = T)),.by = CODE),\n  by = c(\"code\" = \"CODE\"))\n\nsf_practices_size |&gt; \n  filter(NUMBER_OF_PATIENTS&lt;= quantile(NUMBER_OF_PATIENTS,0.9,na.rm = T)) |&gt; \ntm_shape()+\n  tm_symbols(fill = \"NUMBER_OF_PATIENTS\",\n          size = \"NUMBER_OF_PATIENTS\",\n          col = NA,\n          size.scale = tm_scale_continuous(values.scale = 0.5),\n          # fill_alpha = 0.4,\n          fill.scale = tm_scale_intervals(n = 5, values = \"-tol.rainbow_wh_br\"))",
    "crumbs": [
      "GP Practices Analysis",
      "Registered patients"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring the OpenPrescribing Dataset",
    "section": "",
    "text": "This website contains some exploratory analysis of OpenPrescribing data.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "Practices_analysis.html",
    "href": "Practices_analysis.html",
    "title": "GP Practices Classification",
    "section": "",
    "text": "Packages\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\n\nLoading the CAZ boundaries\n\nCAZ_boundaries &lt;- st_read(\"CAZ_boundaries.gpkg\")\n\nReading layer `CAZ_boundaries' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\00_Misc_projects\\Eng-Presc-Data\\CAZ_boundaries.gpkg' \n  using driver `GPKG'\nSimple feature collection with 7 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 356346.4 ymin: 99474.13 xmax: 465151.9 ymax: 565398\nProjected CRS: OSGB36 / British National Grid\n\n\nWe will produce two buffers for each CAZ: 1 km and 10 km.\n\nCAZ_buffer_1k &lt;-  CAZ_boundaries |&gt; \n  st_buffer(1e3)\nCAZ_buffer_5k &lt;-  CAZ_boundaries |&gt; \n  st_buffer(5e3)\n\n\ntmap_mode(\"view\")\n\ntm_shape(CAZ_buffer_5k)+\n  tm_fill(\"dodgerblue\",alpha = 0.3)+\n  tm_shape(CAZ_buffer_1k)+\n  tm_fill(\"dodgerblue3\",alpha = 0.3)+\ntm_shape(CAZ_boundaries)+\n  tm_fill(\"darkblue\")\n\n\n\n\n\nLoading all data from previous analysis\n\nload(\"all_data.RData\")\n\nLet’s classify the CAZ based on their location.\n\nall_practices_raw$within_CAZ &lt;- st_intersects(all_practices_raw,CAZ_boundaries) |&gt; vapply(length,numeric(1)) &gt; 0\nall_practices_raw$within_1km &lt;- st_intersects(all_practices_raw,CAZ_buffer_1k) |&gt; vapply(length,numeric(1)) &gt; 0\nall_practices_raw$within_5km &lt;- st_intersects(all_practices_raw,CAZ_buffer_5k) |&gt; vapply(length,numeric(1)) &gt; 0\n\nall_practices_raw$location_class &lt;- case_when(all_practices_raw$within_CAZ~\"within_CAZ\",\n                                              all_practices_raw$within_1km~\"within_1km\",\n                                              all_practices_raw$within_5km~\"within_5km\",\n                                              TRUE~\"out_CAZ\")\n                                              \n                                              \n\n\nall_practices_raw$CAZ_index &lt;- st_intersects(all_practices_raw,CAZ_buffer_5k) |&gt; vapply(first,integer(1))\nall_practices_raw$CAZ_name &lt;- CAZ_buffer_5k$name[all_practices_raw$CAZ_index]\n\nVisualising the results for the classification\n\ntmap_mode(\"plot\")\ntm_shape(all_practices_raw)+\n  tm_dots(\"location_class\")\n\n\n\n\n\n\n\ntm_shape(all_practices_raw)+\n  tm_dots(\"CAZ_name\")\n\n\n\n\n\n\n\n\n\nst_write(all_practices_raw,\"practices_CAZ.gpkg\",append = F)\n\nDeleting layer `practices_CAZ' using driver `GPKG'\nWriting layer `practices_CAZ' to data source `practices_CAZ.gpkg' using driver `GPKG'\nWriting 11864 features with 10 fields and geometry type Point.\n\n\nSaving the results as a release of the repo\n\nsystem(\"gh release upload v0 practices_CAZ.gpkg --clobber\")",
    "crumbs": [
      "GP Practices Analysis",
      "GP Practices location analysis"
    ]
  },
  {
    "objectID": "Bradford_analysis.html",
    "href": "Bradford_analysis.html",
    "title": "Bradford",
    "section": "",
    "text": "This work is based on data from OpenPrescribing.",
    "crumbs": [
      "Bradford"
    ]
  },
  {
    "objectID": "Bradford_analysis.html#obtaining-boundaries",
    "href": "Bradford_analysis.html#obtaining-boundaries",
    "title": "Bradford",
    "section": "Obtaining boundaries",
    "text": "Obtaining boundaries\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tmap)\nlibrary(OpenStreetMap)\n\n\nNHS boundaries\n\nCCG_boundaries &lt;- geojsonsf::geojson_sf(\"https://openprescribing.net/api/1.0/org_location/?org_type=ccg\") |&gt; st_transform(27700)\n\nWarning in readLines(con): incomplete final line found on\n'https://openprescribing.net/api/1.0/org_location/?org_type=ccg'",
    "crumbs": [
      "Bradford"
    ]
  },
  {
    "objectID": "Bradford_analysis.html#gp-surgeries",
    "href": "Bradford_analysis.html#gp-surgeries",
    "title": "Bradford",
    "section": "GP surgeries",
    "text": "GP surgeries\nApproximate locations of all registered GP surgeries can be obtained. For example, for Bradford (ICB code: 36J)\n\nbradford_code &lt;- \"36J\"\n\nReading the built-up areas data\n\nbuiltup_bounds &lt;- st_read(\"OS Open Built Up Areas.gpkg\",\n                          layer = \"os_open_built_up_areas\")\n\nReading layer `os_open_built_up_areas' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\00_Misc_projects\\Eng-Presc-Data\\OS Open Built Up Areas.gpkg' \n  using driver `GPKG'\nSimple feature collection with 8585 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 65300 ymin: 10000 xmax: 655625 ymax: 1177650\nProjected CRS: OSGB36 / British National Grid\n\n\nSelecting the biggest builtup area within the NHS region\n\nbradford_zones &lt;- builtup_bounds[CCG_boundaries[CCG_boundaries$code==bradford_code,],] |&gt; slice_max(geometry_area_m)\n\n\nBradford_Practices &lt;- geojsonsf::geojson_sf(\n  paste0(\"https://openprescribing.net/api/1.0/org_location/?q=\",\n         bradford_code)\n  ) |&gt; st_transform(27700)\n\nWarning in readLines(con): incomplete final line found on\n'https://openprescribing.net/api/1.0/org_location/?q=36J'\n\n\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\nqtm(Bradford_Practices |&gt; st_make_valid())\n\n\n\n\n\n\nShort acting beta agonist inhalers\nSee: https://openprescribing.net/measure/saba/definition/\nTaken from the web:\n\nWhy it matters: Why Asthma Still Kills reports that high use of short acting beta agonists (salbutamol and terbutaline) and poor adherence to inhaled corticosteroids in asthma suggests poor control - these patients should be reviewed regularly to ensure good control.\nThe NHS England National Medicines Optimisation Opportunities for 2023/24 identify improving patient outcomes from the use of inhalers as an area for improvement.\nDescription: Prescribing of short acting beta agonist (SABA) inhalers - salbutamol and terbutaline - compared with prescribing of inhaled corticosteroid inhalers and SABA inhalers\n\n\nsaba &lt;- read_csv(\n  paste0(\"https://openprescribing.net/api/1.0/measure_by_practice/?format=csv&org=\",\n         bradford_code,\n         \"&parent_org_type=ccg&measure=saba\")) \n\nRows: 5368 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): measure, org_type, org_id, org_name\ndbl  (4): numerator, denominator, calc_value, percentile\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nExploring the data\nIt is possible to extract the trends of both metrics. Below a graphical extract of one of the metrics for Bradford.\n\nhead(saba)\n\n# A tibble: 6 × 9\n  measure org_type org_id org_name   date       numerator denominator calc_value\n  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;      &lt;date&gt;         &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 saba    practice B83021 FARFIELD … 2020-01-01       896        1605      0.558\n2 saba    practice B82020 CROSS HIL… 2020-01-01       679        1315      0.516\n3 saba    practice B82028 FISHER ME… 2020-01-01       537        1392      0.386\n4 saba    practice B82053 DYNELEY H… 2020-01-01       393         930      0.423\n5 saba    practice B82099 GRASSINGT… 2020-01-01         0           0     NA    \n6 saba    practice B83002 ILKLEY & … 2020-01-01       115         275      0.418\n# ℹ 1 more variable: percentile &lt;dbl&gt;\n\nsaba |&gt; \n  ggplot(aes(x = date,\n             y = calc_value,\n             groups = org_id))+\n  geom_line(alpha = 0.15, col = \"dodgerblue2\",linewidth = 0.65)+\n  stat_smooth(geom = \"line\",method = \"lm\",alpha = 0.2, col = \"dodgerblue4\",linewidth = 0.7)+ \n  theme_minimal()+\n  labs(title = \"Ratio of Prescribed SABA over inhaled corticosteroid inhalers + SABA\",\n       y = \"value\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1423 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1417 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\nCalculating an overall trend\nFirst let’s check the data quality for all practices and remove the NAs.\n\nsaba |&gt;\n  drop_na() |&gt;\n  summarise(n_reports = n(),\n            .by = org_id) |&gt;\n  arrange(n_reports) \n\n# A tibble: 73 × 2\n   org_id n_reports\n   &lt;chr&gt;      &lt;int&gt;\n 1 B83007         4\n 2 B83040         7\n 3 B83021        22\n 4 B83006        22\n 5 B82020        23\n 6 B82028        23\n 7 B83023        24\n 8 B83027        24\n 9 B83602        26\n10 B83061        27\n# ℹ 63 more rows\n\n\nWe create a vector with the ids that have more than 10 records\n\nids_to_include &lt;- saba |&gt;\n  drop_na() |&gt;\n  summarise(n_reports = n(),\n            .by = org_id) |&gt;\n  arrange(n_reports) |&gt; \n  filter(n_reports&gt;10) |&gt; \n  pull(org_id)\n\n\n\nSub-setting only the relevant practices\nExtracting the start month from the dataset\n\nstart_month &lt;- min(saba$date)\n\nDefining a function to calculate the month number of the record\n\ndiff_month &lt;- function(start, end){\n  length(seq(from=start, to=end, by='month')) - 1\n}\n\nCalculating the month difference\n\nsaba$month &lt;- vapply(saba$date,\\(x){\n  diff_month(start_month,x)},numeric(1))\n\nSubsetting the practices within the built-up area\n\ncity_practices &lt;- Bradford_Practices[bradford_zones,] |&gt; pull(code)\n\n\nclean_data &lt;- saba |&gt;\n  filter(org_id %in% ids_to_include,org_id %in% city_practices)\n\n\nsaba_processed &lt;- clean_data |&gt; \n  nest(data = -org_id) |&gt; \n  mutate(lm.model = map(.x = data,\n                        \\(x) {\n                          lm(calc_value ~ month, data = x)\n                          }),\n         coef = map_dbl(lm.model,\\(x){coef(x)[2]})\n  )\n\nJoining trends\n\nbradford_trends &lt;- Bradford_Practices |&gt;\n  inner_join(\n    saba_processed |&gt;\n      select(org_id,coef),\n    by = c(\"code\"=\"org_id\"))\n\nMapping the trends\n\nbase_osm &lt;- tmaptools::read_osm(bradford_trends)\n\ntm_shape(base_osm)+\n  tm_rgb()+\n  tm_shape(bradford_trends |&gt; \n  mutate(abs.size = abs(coef))\n  )+\n  tm_dots(col = \"coef\",\n          midpoint = 0,\n          palette = \"Spectral\",\n          size = \"abs.size\",\n          style = \"fisher\")+tm_layout(bg.color = \"gray\")\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_dots()`: instead of `style = \"fisher\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'midpoint', 'palette' (rename to 'values')\n  to 'tm_scale_intervals(&lt;HERE&gt;)'\nFor small multiples, specify a 'tm_scale_' for each multiple, and put them in a\nlist: 'fill'.scale = list(&lt;scale1&gt;, &lt;scale2&gt;, ...)'\n[v3-&gt;v4] `tm_dots()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Spectral\" is named\n\"brewer.spectral\"\nMultiple palettes called \"spectral\" found: \"brewer.spectral\", \"matplotlib.spectral\". The first one, \"brewer.spectral\", is returned.\n\n\n\n\n\n\n\n\nA check of the distribution of the trends\n\nsaba_processed |&gt; \n  filter(org_id %in% bradford_trends$code) |&gt; \n  ggplot(aes(coef,fill = cut(coef,\n                             breaks = seq(-0.02,0.02,0.0005))))+\n  geom_histogram(breaks =  seq(-0.02,0.02,0.0005))+\n  theme_minimal()+\n  scale_x_continuous(labels = scales::percent)+\n  scale_fill_brewer(palette = \"RdYlBu\",direction = -1)+\n  labs(x = \"coef (avg % change per month)\")+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nsaba_processed |&gt;\n  filter(org_id %in% bradford_trends$code) |&gt; \n  ggplot(aes(coef))+\n  stat_ecdf(geom = \"step\")+\n  theme_minimal()+\n  geom_vline(xintercept = 0,alpha = 0.4,col =\"red\",linewidth = 1)+\n  scale_x_continuous(labels = scales::percent)+\n  scale_fill_brewer(palette = \"RdYlBu\",direction = -1)+\n  labs(x = \"coef (avg % change per month)\")+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nCalculating the overall trend\n\ndata_overall &lt;- clean_data |&gt;\n  summarise(across(numerator:denominator,sum),\n            .by = c(date, month)) |&gt; \n  mutate(calc_value = numerator/denominator)\n\n\ndata_overall |&gt; \n  ggplot(aes(date,calc_value))+\n  geom_line(alpha = 0.3,\n            col = \"dodgerblue3\")+\n  geom_smooth(method = \"lm\",se = F,col = \"dodgerblue4\")+\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFitting a simple linear model\n\nlm(calc_value~month,data = data_overall) |&gt; \n  summary()\n\n\nCall:\nlm(formula = calc_value ~ month, data = data_overall)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.021393 -0.006513 -0.001358  0.007201  0.021795 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.306e-01  2.778e-03   191.0   &lt;2e-16 ***\nmonth       -1.134e-03  7.986e-05   -14.2   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01098 on 59 degrees of freedom\nMultiple R-squared:  0.7736,    Adjusted R-squared:  0.7698 \nF-statistic: 201.6 on 1 and 59 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nCAZ boundaries analysis\nCAZ boundaries have been obtained from here\nReading the CAZ boundaries\n\nCAZ_bounds &lt;- sf::st_read(\"Clean_Air_Zone_Boundary.geojson\") |&gt; sf::st_transform(27700)\n\nReading layer `Clean_Air_Zone_Boundary' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\00_Misc_projects\\Eng-Presc-Data\\Clean_Air_Zone_Boundary.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -1.818735 ymin: 53.7682 xmax: -1.717377 ymax: 53.84148\nGeodetic CRS:  WGS 84\n\n\n\nmapview::mapview(CAZ_bounds)\n\n\n\n\n\nIdentifying practices within the CAZ\n\nids_within_CAZ &lt;- bradford_trends[CAZ_bounds,] |&gt; pull(code)\n\nAdding a column to identify the ones within and outside the CAZ\n\nbradford_trends$withinCAZ &lt;- bradford_trends$code %in% ids_within_CAZ\n\nExploring the distribution of coefficients (avg change per month in SABA):\n\nbradford_trends |&gt; \n  ggplot(aes(coef,col = withinCAZ))+\n  geom_vline(xintercept = 0,col = \"goldenrod\",alpha = 0.6,linewidth = 1)+\n  stat_ecdf()+\n  theme_minimal()",
    "crumbs": [
      "Bradford"
    ]
  },
  {
    "objectID": "Multiple_regions_analysis.html",
    "href": "Multiple_regions_analysis.html",
    "title": "Multiple Regions",
    "section": "",
    "text": "Based on the main analysis\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tmap)",
    "crumbs": [
      "Multiple regions",
      "Extracting data"
    ]
  },
  {
    "objectID": "Multiple_regions_analysis.html#nhs-boundaries",
    "href": "Multiple_regions_analysis.html#nhs-boundaries",
    "title": "Multiple Regions",
    "section": "NHS boundaries",
    "text": "NHS boundaries\nboundaries for the NSH regions\n\nCCG_boundaries &lt;- geojsonsf::geojson_sf(\n  \"https://openprescribing.net/api/1.0/org_location/?org_type=ccg\"\n  ) |&gt;\n  st_transform(27700)",
    "crumbs": [
      "Multiple regions",
      "Extracting data"
    ]
  },
  {
    "objectID": "Multiple_regions_analysis.html#loading-the-built-up-areas",
    "href": "Multiple_regions_analysis.html#loading-the-built-up-areas",
    "title": "Multiple Regions",
    "section": "Loading the built-up areas",
    "text": "Loading the built-up areas\nReading the built-up areas data\n\nbuiltup_bounds &lt;- st_read(\"OS Open Built Up Areas.gpkg\",\n                          layer = \"os_open_built_up_areas\")\n\nReading layer `os_open_built_up_areas' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\00_Misc_projects\\Eng-Presc-Data\\OS Open Built Up Areas.gpkg' \n  using driver `GPKG'\nSimple feature collection with 8585 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 65300 ymin: 10000 xmax: 655625 ymax: 1177650\nProjected CRS: OSGB36 / British National Grid\n\n\n\nIdentifying the largest built-up areas within each region\n\nall_BA_selected &lt;- do.call(\n  bind_rows,\n  lapply(CCG_boundaries$code,\n         \\(t_code){\n           \n           t_nhs &lt;- CCG_boundaries[CCG_boundaries$code==t_code,]\n           t_nhs_buffered &lt;- st_buffer(t_nhs,dist = 2e3)               \n                          \n           # Subsetting the biggest built-up NHS area\n           builtup_bounds[t_nhs,\n                          ][t_nhs_buffered,\n                            op = st_within] |&gt;\n             slice_max(geometry_area_m) |&gt;\n                        mutate(\n                          org_code  = t_code) \n  }))\n\nA quick check of the largest built-up areas within each NHS region\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(CCG_boundaries)+\n  tm_polygons(border.col = \"black\",col = \"white\",alpha = 0.2)+\n  tm_shape(all_BA_selected)+\n  tm_fill(\"dodgerblue3\")\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').[v3-&gt;v4] `tm_polygons()`: use `fill_alpha` instead of `alpha`.",
    "crumbs": [
      "Multiple regions",
      "Extracting data"
    ]
  },
  {
    "objectID": "Multiple_regions_analysis.html#running-the-analisys-for-all-regions",
    "href": "Multiple_regions_analysis.html#running-the-analisys-for-all-regions",
    "title": "Multiple Regions",
    "section": "Running the analisys for all regions",
    "text": "Running the analisys for all regions\n\nall_saba_raw &lt;- do.call(\n  bind_rows,\n  lapply(CCG_boundaries$code, \\(t_code) {\n    read_csv(\n      paste0(\n        \"https://openprescribing.net/api/1.0/measure_by_practice/?format=csv&org=\",\n        t_code,\n        \"&parent_org_type=ccg&measure=saba\"\n      ),\n      col_types = cols(\n        measure = col_character(),\n        org_type = col_character(),\n        org_id = col_character(),\n        org_name = col_character(),\n        date = col_date(format = \"\"),\n        numerator = col_double(),\n        denominator = col_double(),\n        calc_value = col_double(),\n        percentile = col_double()\n      )\n    )\n  }))\n\n\nall_practices_raw &lt;- do.call(\n  bind_rows,\n  lapply(CCG_boundaries$code, \\(t_code) {\n    geojsonsf::geojson_sf(\n      paste0(\"https://openprescribing.net/api/1.0/org_location/?q=\",\n         t_code)) |&gt;\n      st_transform(27700) |&gt; \n      mutate(par_code = t_code)\n  }))\n\n\nOverall trends\nIdentifying the practices without all records\n\ncount_records &lt;- all_saba_raw |&gt;\n        drop_na() |&gt;\n        summarise(n_reports = n(), .by = org_id)\n\nPlotting the distribution of records per practice\n\nggplot(count_records,\n       aes(n_reports))+\n  stat_ecdf()+\n  scale_y_continuous(labels = scales::label_percent())\n\n\n\n\n\n\n\n\nExtracting the IDs of the practices with all records\n\npractices_complete &lt;- count_records |&gt;\n  filter(n_reports == max(n_reports)) |&gt; \n  pull(org_id)\n\nCalculating overall trend using the prectices with complete records\n\noverall_saba &lt;- all_saba_raw |&gt;\n  filter(org_id %in% practices_complete) |&gt; \n  summarise(across(numerator:denominator, sum), .by = c(date)) |&gt;\n        mutate(calc_value = numerator / denominator)\n\n\n# Defining function for month delta\ndiff_month &lt;- function(start, end) {\n  length(seq(from = start, to = end, by = 'month')) - 1\n}\n\n# Doing all the month transforming for fitting a model\nstart_month &lt;- min(overall_saba$date)\noverall_saba$month &lt;- vapply(overall_saba$date, \\(x) {\n  diff_month(start_month, x)\n}, numeric(1))\n\nAveraged time series\n\noverall_saba |&gt; \nggplot(aes(x = date, y = calc_value))+\n  geom_line(col = \"dodgerblue2\", alpha = 0.3)+\n  # geom_smooth(method = \"lm\",se = F,\n  #             col = \"dodgerblue4\",\n  #             linewidth = 1)+\n  scale_y_continuous(labels = scales::label_percent())+\n  theme_minimal()\n\n\n\n\n\n\n\n\nAverage linear trend\n\noverall_saba |&gt; \nggplot(aes(x = date, y = calc_value))+\n  geom_line(col = \"dodgerblue2\", alpha = 0.3)+\n  geom_smooth(method = \"lm\",se = F,\n              col = \"dodgerblue4\",\n              linewidth = 1)+\n  scale_y_continuous(labels = scales::label_percent())+\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nTime series analysis using timetk\n\nlibrary(timetk)\nanomalised_saba &lt;- overall_saba |&gt; anomalize(date,calc_value)\n\nfrequency = 12 observations per 1 year\n\n\ntrend = 12 observations per 1 year\n\n\nDecomposing the time series\n\nanomalised_saba |&gt;\nplot_anomalies_decomp(\n.date_var = date,\n.interactive = FALSE\n)\n\n\n\n\n\n\n\n\nShowing anomalies\n\nanomalised_saba |&gt;\n  plot_anomalies(date,\n                 .interactive = F)\n\n\n\n\n\n\n\n\n\n\n\nComparing NHS regions\nSummarising trends for the major built-up area in each region\n\nall_ccg_summarised &lt;- do.call(\n  bind_rows,\n  lapply(\n    CCG_boundaries$code,\n    \\(t_code){\n      # Subsetting the biggest built-up NHS area\n      main_BA &lt;- all_BA_selected[all_BA_selected$org_code == t_code, ]\n      \n      # Extracting the practices for that NHS area\n      Practices &lt;- all_practices_raw[all_practices_raw$par_code == t_code, ][main_BA, ]\n      \n      # Extracting the SABA results for that area\n      saba &lt;- all_saba_raw[all_saba_raw$org_id %in% Practices$code, ]\n      # # Identifying the practices with more than 10 records\n      # ids_to_include &lt;- saba |&gt;\n      #   drop_na() |&gt;\n      #   summarise(n_reports = n(), .by = org_id) |&gt;\n      #   arrange(n_reports) |&gt;\n      #   filter(n_reports &gt; 10) |&gt;\n      #   pull(org_id)\n      \n      # Defining function for month delta\n      diff_month &lt;- function(start, end) {\n        length(seq(from = start, to = end, by = 'month')) - 1\n      }\n      \n      # Doing all the month transforming for fitting a model\n      start_month &lt;- min(saba$date)\n      saba$month &lt;- vapply(saba$date, \\(x) {\n        diff_month(start_month, x)\n      }, numeric(1))\n      \n      # Identifying the practices within the main built-up area\n      city_practices &lt;- Practices[main_BA, ] |&gt; pull(code)\n      \n      # Producing a clean SABA dataset\n      # (no outliers nor practices out of main urban area)\n      \n      clean_data &lt;- saba |&gt;\n        filter(org_id %in% practices_complete, org_id %in% city_practices)\n      \n      clean_data |&gt;\n        summarise(across(numerator:denominator, sum), .by = c(date, month)) |&gt;\n        mutate(calc_value = numerator / denominator, org_code  = t_code)\n    }\n  )\n)\n\nJoining with the CCG table to obtain the names\n\nall_data_names &lt;- all_ccg_summarised |&gt;\n  left_join(CCG_boundaries |&gt;\n              st_drop_geometry() |&gt;\n              select(name,code),by = c(\"org_code\"=\"code\"))\n\nA quick visualisation of the linear trends of Bradford and Liverpool\n\nall_data_names|&gt; \n  ggplot(aes(x = date,y = calc_value,group = org_code))+\n  geom_line(col = \"dodgerblue2\",alpha = 0.3)+\n  geom_smooth(data =all_data_names |&gt; \n                filter(org_code %in% c(\"36J\",\"99A\")),\n              aes(col = name,fill = name),\n              method = \"lm\",\n              # se = F,\n              # col = \"dodgerblue4\",\n              linewidth = 1)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nProcessing Built-up areas with CAZ\n\nCAZ_lst &lt;- read_csv(\"CAZ_list.csv\") |&gt; select(Area, Type)\n\nRows: 14 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): CAZ, Area, Type, file\ndbl (1): Start\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nSub-setting the built-up areas with CAZ zones\n\nCAZ_BA &lt;- builtup_bounds |&gt; semi_join(CAZ_lst,by=c(\"gsscode\"=\"Area\"))\n\n\nall_caz_summarised &lt;- do.call(\n  bind_rows,\n  lapply(\n    CAZ_BA$gsscode,\n    \\(t_code){\n      # Subsetting the biggest built-up NHS area\n      main_BA &lt;- CAZ_BA[CAZ_BA$gsscode == t_code, ]\n      \n      # Extracting the practices for that NHS area\n      Practices &lt;- all_practices_raw[main_BA, ]\n      \n      # Extracting the SABA results for that area\n      saba &lt;- all_saba_raw[all_saba_raw$org_id %in% Practices$code, ]\n      \n      # Defining function for month delta\n      diff_month &lt;- function(start, end) {\n        length(seq(from = start, to = end, by = 'month')) - 1\n      }\n      \n      # Doing all the month transforming for fitting a model\n      start_month &lt;- min(saba$date)\n      saba$month &lt;- vapply(saba$date, \\(x) {\n        diff_month(start_month, x)\n      }, numeric(1))\n      \n      \n      # Producing a clean SABA dataset\n      # (no outliers nor practices out of main urban area)\n      \n      clean_data &lt;- saba |&gt;\n        filter(org_id %in% practices_complete)\n      \n      clean_data |&gt;\n        summarise(across(numerator:denominator, sum), .by = c(date, month)) |&gt;\n        mutate(calc_value = numerator / denominator,\n               name  = CAZ_BA$name1_text[CAZ_BA$gsscode == t_code],\n               type = CAZ_lst$Type[CAZ_lst$Area==t_code])\n    }\n  )\n)",
    "crumbs": [
      "Multiple regions",
      "Extracting data"
    ]
  },
  {
    "objectID": "Trends_practices.html",
    "href": "Trends_practices.html",
    "title": "GP Practices Trends",
    "section": "",
    "text": "library(sf)\nlibrary(tidyverse)\nlibrary(tmap)"
  },
  {
    "objectID": "Trends_practices.html#loading-data",
    "href": "Trends_practices.html#loading-data",
    "title": "GP Practices Trends",
    "section": "Loading data",
    "text": "Loading data"
  },
  {
    "objectID": "Trends_practices.html#prescription-data",
    "href": "Trends_practices.html#prescription-data",
    "title": "GP Practices Trends",
    "section": "Prescription data",
    "text": "Prescription data\n\nload(\"all_data.RData\")"
  },
  {
    "objectID": "Trends_practices.html#practice-data",
    "href": "Trends_practices.html#practice-data",
    "title": "GP Practices Trends",
    "section": "Practice data",
    "text": "Practice data\n\npract_classed &lt;- st_read(\"practices_CAZ.gpkg\")\n\nReading layer `practices_CAZ' from data source \n  `C:\\Users\\ts18jpf\\OneDrive - University of Leeds\\03_PhD\\00_Misc_projects\\Eng-Presc-Data\\practices_CAZ.gpkg' \n  using driver `GPKG'\nSimple feature collection with 11864 features and 10 fields (with 4 geometries empty)\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 90774 ymin: 10282 xmax: 655043 ymax: 653236\nProjected CRS: OSGB36 / British National Grid\n\nCAZ_lst &lt;- read_csv(\"CAZ_list.csv\")"
  },
  {
    "objectID": "Trends_practices.html#patient-data",
    "href": "Trends_practices.html#patient-data",
    "title": "GP Practices Trends",
    "section": "Patient data",
    "text": "Patient data\n\npatient_num_df &lt;- read_csv(\"practice_patients.csv\")\n\npatient_num_df$month &lt;- match(patient_num_df$month,tolower(month.name))"
  },
  {
    "objectID": "Trends_practices.html#subsetting-data",
    "href": "Trends_practices.html#subsetting-data",
    "title": "GP Practices Trends",
    "section": "Subsetting data",
    "text": "Subsetting data\n\nCAZ_practices &lt;- pract_classed |&gt;\n  mutate(location_class = factor(location_class,\n                                 levels = c(\"within_CAZ\",\"within_1km\",\"within_5km\",\"out_CAZ\"),\n                                 ordered = T)) |&gt; \n  filter(location_class != \"out_CAZ\")\n  \n\nCAZ_patients &lt;- patient_num_df |&gt; filter(CODE %in% CAZ_practices$code)\n\nCAZ_SABA &lt;- all_saba_raw |&gt; \n  filter(org_id %in% CAZ_practices$code) |&gt; \n  mutate(month = month(date),\n         year = year(date)) |&gt; \n  left_join(CAZ_patients,by = c(\"org_id\" = \"CODE\",\"month\",\"year\"))\n\n\nplots_SABA &lt;- CAZ_SABA |&gt; \n  left_join(CAZ_practices |&gt; st_drop_geometry() |&gt; \n              select(code,location_class,CAZ_name),by = c(\"org_id\"=\"code\")) |&gt; \n  nest(data = -CAZ_name) |&gt; \n  left_join(CAZ_lst |&gt; select(CAZ,Start),by = c(\"CAZ_name\"= \"CAZ\")) |&gt; \n  mutate(trend_data = map2(data,Start,\n                           \\(.x,.y){\n                             .x |&gt; \n                               filter(year&gt;=.y)\n                           })) |&gt; \n  mutate(plots = map2(data,trend_data,\n                      \\(.x, .y){\n                        .x |&gt; ggplot(aes(x = date, y = calc_value,colour = location_class))+\n                          geom_line(aes(group = org_id),alpha = 0.2,linewidth = 0.2)+\n                          geom_smooth(data = .y,aes(weight = NUMBER_OF_PATIENTS),\n                                      method = \"lm\", se = F)+\n                          theme_minimal()+\n                          scale_color_brewer(palette = \"Set1\")\n  })) |&gt; \n  mutate(plots = map2(plots,CAZ_name,\\(.x,.y){\n                      .x + labs(title = .y,\n                                y = \"SABA ratio\",\n                                col = \"Location Class\",\n                                x = \"\")}\n                      ))\n  \n\nmap2(plots_SABA$CAZ_name,plots_SABA$plots,\\(.x,.y){\n  ggsave(plot = .y,filename = paste(\"SABA_trend_\",.x,\".png\"),dpi = 330,units = \"cm\",width = 18,height = 10)\n})\n\n[[1]]\n[1] \"SABA_trend_ Birmingham .png\"\n\n[[2]]\n[1] \"SABA_trend_ Portsmouth .png\"\n\n[[3]]\n[1] \"SABA_trend_ Newcastle upon Tyne .png\"\n\n[[4]]\n[1] \"SABA_trend_ Bradford .png\"\n\n[[5]]\n[1] \"SABA_trend_ Sheffield .png\"\n\n[[6]]\n[1] \"SABA_trend_ BANES .png\"\n\n[[7]]\n[1] \"SABA_trend_ Bristol .png\"\n\n\n\nplots_SABA_num &lt;- CAZ_SABA |&gt; \n  left_join(CAZ_practices |&gt; st_drop_geometry() |&gt; \n              select(code,location_class,CAZ_name),by = c(\"org_id\"=\"code\")) |&gt; \n  nest(data = -CAZ_name) |&gt; \n  left_join(CAZ_lst |&gt; select(CAZ,Start),by = c(\"CAZ_name\"= \"CAZ\")) |&gt; \n  mutate(trend_data = map2(data,Start,\n                           \\(.x,.y){\n                             .x |&gt; \n                               filter(year&gt;=.y)\n                           })) |&gt; \n  mutate(plots = map2(data,trend_data,\n                      \\(.x, .y){\n                        .x |&gt; ggplot(aes(x = date,\n                                         y = numerator / NUMBER_OF_PATIENTS,\n                                         colour = location_class))+\n                          geom_line(aes(group = org_id),alpha = 0.2,linewidth = 0.2)+\n                          geom_smooth(data = .y,aes(weight = NUMBER_OF_PATIENTS),\n                                      method = \"lm\", se = F)+\n                          theme_minimal()+\n                          scale_y_sqrt()+\n                          scale_color_brewer(palette = \"Set1\")\n  })) |&gt; \n  mutate(plots = map2(plots,CAZ_name,\\(.x,.y){\n                      .x + labs(title = .y,\n                                y = \"SABA total prescriptions / patient\",\n                                col = \"Location Class\",\n                                x = \"\")}\n                      ))\n  \n\nmap2(plots_SABA_num$CAZ_name,plots_SABA_num$plots,\\(.x,.y){\n  ggsave(plot = .y,filename = paste(\"SABA_numerator_trend_\",.x,\".png\"),dpi = 330,units = \"cm\",width = 18,height = 10)\n})\n\n[[1]]\n[1] \"SABA_numerator_trend_ Birmingham .png\"\n\n[[2]]\n[1] \"SABA_numerator_trend_ Portsmouth .png\"\n\n[[3]]\n[1] \"SABA_numerator_trend_ Newcastle upon Tyne .png\"\n\n[[4]]\n[1] \"SABA_numerator_trend_ Bradford .png\"\n\n[[5]]\n[1] \"SABA_numerator_trend_ Sheffield .png\"\n\n[[6]]\n[1] \"SABA_numerator_trend_ BANES .png\"\n\n[[7]]\n[1] \"SABA_numerator_trend_ Bristol .png\""
  },
  {
    "objectID": "detailed_results.html",
    "href": "detailed_results.html",
    "title": "Results",
    "section": "",
    "text": "This section allows you to explore the overall trend for multiple areas simultaneously. Average trends have been calculated for practices with all records within the main built-up area.",
    "crumbs": [
      "Multiple regions",
      "Results"
    ]
  },
  {
    "objectID": "detailed_results.html#results-by-built-up-areas-with-caz",
    "href": "detailed_results.html#results-by-built-up-areas-with-caz",
    "title": "Results",
    "section": "Results by Built-up Areas with CAZ",
    "text": "Results by Built-up Areas with CAZ\n\nviewof caztype = Inputs.select(caztypes, {value: \"CAZ D\", label: \"Type\"})\n\n\n\n\n\n\n\ncazfiltered = transpose(cazdata).filter(function(record) {\nreturn caztype.includes(record.type) ;\n})\n\n\n\n\n\n\n\nPlot.plot({\n  y: {domain: [0,70],\n    grid: true,\n    label: \"SABA ratio(%)\",\n    transform: (f) =&gt; (f*100)\n  },\n  x: {\n  transform: (x) =&gt; d3.timeParse(\"%Y-%m-%d\")(x),\n  interval: \"month\"\n  },\n  color: {legend: true},\n  marks: [\n    Plot.ruleY([0]),\n    Plot.lineY(cazfiltered,\n    {x: \"date\",\n    y: \"calc_value\",\n    stroke: \"name\",\n    marker: \"dot\",\n    strokeOpacity: 0.3}),\n    Plot.linearRegressionY(cazfiltered,\n    {x: \"date\",\n    y: \"calc_value\",\n    stroke: \"name\"})\n    ]\n})\n\n\n\n\n\n\nLinear trends (Avg % Change per month)",
    "crumbs": [
      "Multiple regions",
      "Results"
    ]
  },
  {
    "objectID": "detailed_results.html#trends-in-each-nhs-region",
    "href": "detailed_results.html#trends-in-each-nhs-region",
    "title": "Results",
    "section": "Trends in each NHS region",
    "text": "Trends in each NHS region\nSelect the start month to calculate the linear trend\n\nviewof month_min = Inputs.range(\n  [0, 60],\n  {value: 28, step: 1, label: \"Start month:\"}\n)\n\n\n\n\n\n\nSelect the NHS regions of interest (max 6):\n\nviewof names = Inputs.select(lstNames, {multiple: 6, label: \"NHS Regions\",value: [\"NHS BRADFORD DISTRICT AND CRAVEN\",\"NHS LIVERPOOL\"]})\n\n\n\n\n\n\n\nrfiltered = transpose(mydata).filter(function(record) {\nreturn month_min &lt; record.month && names.includes(record.name) ;\n})\n\n\n\n\n\n\n\nPlot.plot({\n  y: {domain: [0,70],\n    grid: true,\n    label: \"SABA ratio(%)\",\n    transform: (f) =&gt; (f*100)\n  },\n  x: {\n  transform: (x) =&gt; d3.timeParse(\"%Y-%m-%d\")(x),\n  interval: \"month\"\n  },\n  color: {legend: true},\n  marks: [\n    Plot.ruleY([0]),\n    Plot.lineY(transpose(mydata),\n    {x: \"date\",\n    y: \"calc_value\",\n    stroke: \"#aaa7ad\",\n    z: \"name\",\n    strokeOpacity: 0.2}),\n    Plot.lineY(rfiltered,\n    {x: \"date\",\n    y: \"calc_value\",\n    stroke: \"name\",\n    marker: \"dot\",\n    strokeOpacity: 0.6}),\n    Plot.linearRegressionY(rfiltered,\n    {x: \"date\",\n    y: \"calc_value\",\n    stroke: \"name\"})\n    ]\n})",
    "crumbs": [
      "Multiple regions",
      "Results"
    ]
  }
]